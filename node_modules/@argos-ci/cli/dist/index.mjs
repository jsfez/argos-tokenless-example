import { readFile } from 'node:fs/promises';
import { fileURLToPath } from 'node:url';
import { resolve } from 'node:path';
import { program } from 'commander';
import convict from 'convict';
import envCi from 'env-ci';
import { execSync } from 'child_process';
import glob from 'fast-glob';
import { promisify } from 'node:util';
import sharp from 'sharp';
import tmp from 'tmp';
import { createReadStream } from 'node:fs';
import { createHash } from 'node:crypto';
import axios from 'axios';
import createDebug from 'debug';
import ora from 'ora';

const mustBeApiBaseUrl = (value)=>{
    const URL_REGEX = /https?:\/\/(www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b([-a-zA-Z0-9()@:%_\+.~#?&//=]*)/;
    if (!URL_REGEX.test(value)) {
        throw new Error("Invalid Argos API base URL");
    }
};
const mustBeCommit = (value)=>{
    const SHA1_REGEX = /^[0-9a-f]{40}$/;
    if (!SHA1_REGEX.test(value)) {
        const SHA1_SHORT_REGEX = /^[0-9a-f]{7}$/;
        if (SHA1_SHORT_REGEX.test(value)) {
            throw new Error("Short SHA1 is not allowed");
        }
        throw new Error("Invalid commit");
    }
};
const mustBeArgosToken = (value)=>{
    if (value && value.length !== 40) {
        throw new Error("Must be a valid Argos repository token");
    }
};
const schema = {
    apiBaseUrl: {
        env: "ARGOS_API_BASE_URL",
        default: "https://api.argos-ci.com/v2/",
        format: mustBeApiBaseUrl
    },
    commit: {
        env: "ARGOS_COMMIT",
        default: "",
        format: mustBeCommit
    },
    branch: {
        env: "ARGOS_BRANCH",
        default: null,
        format: String,
        nullable: true
    },
    token: {
        env: "ARGOS_TOKEN",
        default: null,
        format: mustBeArgosToken
    },
    buildName: {
        env: "ARGOS_BUILD_NAME",
        default: null,
        format: String,
        nullable: true
    },
    parallel: {
        env: "ARGOS_PARALLEL",
        default: false,
        format: Boolean
    },
    parallelNonce: {
        env: "ARGOS_PARALLEL_NONCE",
        format: String,
        default: null,
        nullable: true
    },
    parallelTotal: {
        env: "ARGOS_PARALLEL_TOTAL",
        format: "nat",
        default: null,
        nullable: true
    },
    ciService: {
        format: String,
        default: null,
        nullable: true
    },
    jobId: {
        format: String,
        default: null,
        nullable: true
    },
    runId: {
        format: String,
        default: null,
        nullable: true
    },
    owner: {
        format: String,
        default: null,
        nullable: true
    },
    repository: {
        format: String,
        default: null,
        nullable: true
    }
};
const createConfig = ()=>{
    return convict(schema, {
        args: []
    });
};

/**
 * Omit undefined properties from an object.
 */ const omitUndefined = (obj)=>{
    const result = {};
    Object.keys(obj).forEach((key)=>{
        if (obj[key] !== undefined) {
            result[key] = obj[key];
        }
    });
    return result;
};

const service$1 = {
    detect: ({ env  })=>Boolean(env.HEROKU_TEST_RUN_ID),
    config: ({ env  })=>({
            name: "Heroku",
            commit: env.HEROKU_TEST_RUN_COMMIT_VERSION || null,
            branch: env.HEROKU_TEST_RUN_BRANCH || null,
            owner: null,
            repository: null,
            jobId: env.HEROKU_TEST_RUN_ID || null,
            runId: null
        })
};

const getSha = ({ env  })=>{
    const isPr = env.GITHUB_EVENT_NAME === "pull_request" || env.GITHUB_EVENT_NAME === "pull_request_target";
    if (isPr) {
        const mergeCommitRegex = /^[a-z0-9]{40} [a-z0-9]{40}$/;
        const mergeCommitMessage = execSync("git show --no-patch --format=%P").toString().trim();
        // console.log(
        //   `Handling PR with parent hash(es) '${mergeCommitMessage}' of current commit.`
        // );
        if (mergeCommitRegex.exec(mergeCommitMessage)) {
            const mergeCommit = mergeCommitMessage.split(" ")[1];
            // console.log(
            //   `Fixing merge commit SHA ${process.env.GITHUB_SHA} -> ${mergeCommit}`
            // );
            return mergeCommit;
        } else if (mergeCommitMessage === "") {
            console.error(`Error: automatic detection of commit SHA failed.

Please run "actions/checkout" with "fetch-depth: 2". Example:

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 2

`);
            process.exit(1);
        } else {
            console.error(`Commit with SHA ${process.env.GITHUB_SHA} is not a valid commit`);
            process.exit(1);
        }
    }
    return process.env.GITHUB_SHA ?? null;
};
function getBranch({ env  }) {
    if (env.GITHUB_HEAD_REF) {
        return env.GITHUB_HEAD_REF;
    }
    const branchRegex = /refs\/heads\/(.*)/;
    const branchMatches = branchRegex.exec(env.GITHUB_REF || "");
    if (branchMatches) {
        return branchMatches[1];
    }
    return null;
}
function getRepository({ env  }) {
    if (!env.GITHUB_REPOSITORY) return null;
    return env.GITHUB_REPOSITORY.split("/")[1];
}
const service = {
    detect: ({ env  })=>Boolean(env.GITHUB_ACTIONS),
    config: ({ env  })=>({
            name: "GitHub Actions",
            commit: getSha({
                env
            }),
            branch: getBranch({
                env
            }),
            owner: env.GITHUB_REPOSITORY_OWNER || null,
            repository: getRepository({
                env
            }),
            jobId: env.GITHUB_JOB || null,
            runId: env.GITHUB_RUN_ID || null
        })
};

const services = [
    service$1,
    service
];
const getCiEnvironment = ({ env =process.env  } = {})=>{
    const ctx = {
        env
    };
    const service = services.find((service)=>service.detect(ctx));
    // Internal service matched
    if (service) {
        return service.config(ctx);
    }
    // Fallback on env-ci detection
    const ciContext = envCi(ctx);
    const name = ciContext.isCi ? ciContext.name ?? null : ciContext.commit ? "Git" : null;
    const commit = ciContext.commit ?? null;
    const branch = (ciContext.branch || ciContext.prBranch) ?? null;
    const slug = ciContext.slug ? ciContext.slug.split("/") : null;
    const owner = slug ? slug[0] : null;
    const repository = slug ? slug[1] : null;
    const jobId = ciContext.job ?? null;
    const runId = null;
    return commit ? {
        name,
        commit,
        branch,
        owner,
        repository,
        jobId,
        runId
    } : null;
};

const discoverScreenshots = async (patterns, { root =process.cwd() , ignore  } = {})=>{
    const matches = await glob(patterns, {
        onlyFiles: true,
        ignore,
        cwd: root
    });
    return matches.map((match)=>({
            name: match,
            path: resolve(root, match)
        }));
};

const tmpFile = promisify(tmp.file);
const optimizeScreenshot = async (filepath)=>{
    const resultFilePath = await tmpFile();
    await sharp(filepath).resize(2048, 20480, {
        fit: "inside",
        withoutEnlargement: true
    }).png({
        force: true
    }).toFile(resultFilePath);
    return resultFilePath;
};

const hashFile = async (filepath)=>{
    const fileStream = createReadStream(filepath);
    const hash = createHash("sha256");
    await new Promise((resolve, reject)=>{
        fileStream.on("error", reject);
        hash.on("error", reject);
        hash.on("finish", resolve);
        fileStream.pipe(hash);
    });
    return hash.digest("hex");
};

const base64Encode = (obj)=>Buffer.from(JSON.stringify(obj), "utf8").toString("base64");
const getBearerToken = ({ token , ciService , owner , repository , jobId , runId  })=>{
    if (token) return `Bearer ${token}`;
    switch(ciService){
        case "GitHub Actions":
            {
                if (!owner || !repository || !jobId || !runId) {
                    throw new Error(`Automatic ${ciService} variables detection failed. Please add the 'ARGOS_TOKEN'`);
                }
                return `Bearer tokenless-github-${base64Encode({
                    owner,
                    repository,
                    jobId,
                    runId
                })}`;
            }
        default:
            throw new Error("Missing Argos repository token 'ARGOS_TOKEN'");
    }
};
const createArgosApiClient = (options)=>{
    const axiosInstance = axios.create({
        baseURL: options.baseUrl,
        headers: {
            Authorization: options.bearerToken,
            "Content-Type": "application/json",
            Accept: "application/json"
        }
    });
    const call = async (method, path, data)=>{
        try {
            const response = await axiosInstance.request({
                method,
                url: path,
                data
            });
            return response.data;
        } catch (error) {
            if (error?.response?.data?.error?.message) {
                // @ts-ignore
                throw new Error(error.response.data.error.message, {
                    cause: error
                });
            }
            throw error;
        }
    };
    return {
        createBuild: async (input)=>{
            return call("POST", "/builds", input);
        },
        updateBuild: async (input)=>{
            const { buildId , ...body } = input;
            return call("PUT", `/builds/${buildId}`, body);
        }
    };
};

const upload$1 = async (input)=>{
    const file = await readFile(input.path);
    await axios({
        method: "PUT",
        url: input.url,
        data: file,
        headers: {
            "Content-Type": "image/png"
        }
    });
};

const debug = createDebug("@argos-ci/core");

const getConfigFromOptions = (options)=>{
    const { apiBaseUrl , commit , branch , token , buildName , parallel  } = options;
    const config = createConfig();
    config.load(omitUndefined({
        apiBaseUrl,
        commit,
        branch,
        token,
        buildName,
        parallel: Boolean(parallel),
        parallelNonce: parallel ? parallel.nonce : null,
        parallelTotal: parallel ? parallel.total : null
    }));
    if (!config.get("commit")) {
        const ciEnv = getCiEnvironment();
        if (ciEnv) {
            config.load(omitUndefined({
                commit: ciEnv.commit,
                branch: ciEnv.branch,
                ciService: ciEnv.name,
                owner: ciEnv.owner,
                repository: ciEnv.repository,
                jobId: ciEnv.jobId,
                runId: ciEnv.runId
            }));
        }
    }
    config.validate();
    return config.get();
};
/**
 * Upload screenshots to argos-ci.com.
 */ const upload = async (params)=>{
    // Read config
    const config = getConfigFromOptions(params);
    const files = params.files ?? [
        "**/*.{png,jpg,jpeg}"
    ];
    const apiClient = createArgosApiClient({
        baseUrl: config.apiBaseUrl,
        bearerToken: getBearerToken(config)
    });
    // Collect screenshots
    const foundScreenshots = await discoverScreenshots(files, {
        root: params.root,
        ignore: params.ignore
    });
    // Optimize & compute hashes
    const screenshots = await Promise.all(foundScreenshots.map(async (screenshot)=>{
        const optimizedPath = await optimizeScreenshot(screenshot.path);
        const hash = await hashFile(optimizedPath);
        return {
            ...screenshot,
            optimizedPath,
            hash
        };
    }));
    // Create build
    debug("Creating build");
    const result = await apiClient.createBuild({
        commit: config.commit,
        branch: config.branch,
        name: config.buildName,
        parallel: config.parallel,
        parallelNonce: config.parallelNonce,
        screenshotKeys: Array.from(new Set(screenshots.map((screenshot)=>screenshot.hash)))
    });
    debug("Got screenshots", result);
    // Upload screenshots
    debug("Uploading screenshots");
    await Promise.all(result.screenshots.map(async ({ key , putUrl  })=>{
        const screenshot = screenshots.find((s)=>s.hash === key);
        if (!screenshot) {
            throw new Error(`Invariant: screenshot with hash ${key} not found`);
        }
        await upload$1({
            url: putUrl,
            path: screenshot.optimizedPath
        });
    }));
    // Update build
    debug("Updating build");
    await apiClient.updateBuild({
        buildId: result.build.id,
        screenshots: screenshots.map((screenshot)=>({
                key: screenshot.hash,
                name: screenshot.name
            })),
        parallel: config.parallel,
        parallelTotal: config.parallelTotal
    });
    return {
        build: result.build,
        screenshots
    };
};

const __dirname = fileURLToPath(new URL(".", import.meta.url));
const rawPkg = await readFile(resolve(__dirname, "..", "package.json"), "utf8");
const pkg = JSON.parse(rawPkg);
program.name(pkg.name).description("Interact with and upload screenshots to argos-ci.com via command line.").version(pkg.version);
program.command("upload").argument("<directory>", "Directory to upload").description("Upload screenshots to argos-ci.com").option("-f, --files <patterns...>", "One or more globs matching image file paths to upload", "**/*.{png,jpg,jpeg}").option("-i, --ignore <patterns...>", 'One or more globs matching image file paths to ignore (ex: "**/*.png **/diff.jpg")').option("--token <token>", "Repository token").option("--build-name <string>", "Name of the build, in case you want to run multiple Argos builds in a single CI job").option("--parallel", "Enable parallel mode. Run multiple Argos builds and combine them at the end").option("--parallel-total <number>", "The number of parallel nodes being ran").option("--parallel-nonce <string>", "A unique ID for this parallel build").action(async (directory, options)=>{
    const spinner = ora("Uploading screenshots").start();
    try {
        const result = await upload({
            root: directory,
            buildName: options.buildName,
            files: options.files,
            ignore: options.ignore,
            parallel: options.parallel ? {
                nonce: options.parallelNonce,
                total: options.parallelTotal
            } : false
        });
        spinner.succeed(`Build created: ${result.build.url}`);
    } catch (error) {
        spinner.fail(`Build failed: ${error.message}`);
        console.error(error.stack);
        process.exit(1);
    }
});
if (!process.argv.slice(2).length) {
    program.outputHelp();
} else {
    program.parse(process.argv);
}
